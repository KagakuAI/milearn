{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93982e6b-0937-427f-aa5f-89fa55a4117f",
   "metadata": {},
   "source": [
    "### LazyMIL: Automated MIL Benchmarking and Smart Consensus Modeling\n",
    "\n",
    "The **LazyMIL** module provides a convenient, high-level interface for applying **Multiple Instance Learning (MIL)** to real-world or benchmark datasets.  \n",
    "It seamlessly combines **descriptor calculation**, **model training**, and **evaluation** into one streamlined workflow â€” ideal for competitions, benchmarks, or quick exploratory studies.\n",
    "\n",
    "LazyMIL automatically:\n",
    "- Handles **descriptor calculation** for molecules or fragments.  \n",
    "- Trains **multiple MIL estimators** in parallel.  \n",
    "- Collects predictions and metrics for model comparison.  \n",
    "- Optionally integrates **smart consensus optimization** using a genetic algorithm.\n",
    "\n",
    "For consensus modeling, LazyMIL leverages the **QSARcons** package â€” a flexible framework for discovering optimal model ensembles.\n",
    "\n",
    "> ðŸ§© **Install QSARcons before running this tutorial:**\n",
    "> ```bash\n",
    "> pip install qsarcons\n",
    "> ```\n",
    "\n",
    "**In summary:**  \n",
    "LazyMIL simplifies the process of testing, comparing, and combining MIL models, making it a practical tool for QSAR researchers and ML competitions alike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a34672-21e0-49ca-a53e-597f08aa65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from qsarmil.lazy import LazyMIL\n",
    "from qsarcons.consensus import RandomSearchRegressor, SystematicSearchRegressor, GeneticSearchRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5be903-f368-4a1b-812a-35b404569643",
   "metadata": {},
   "source": [
    "### 1. Loading ACE Dataset\n",
    "\n",
    "ACE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56c7ad-f999-456e-a685-6e13ebc4f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://raw.githubusercontent.com/molML/MoleculeACE/main/MoleculeACE/Data/benchmark_data/CHEMBL2034_Ki.csv\"\n",
    "dataset = pd.read_csv(dataset_url)\n",
    "\n",
    "data_train = dataset[dataset[\"split\"] == \"train\"][[\"smiles\", \"y\"]]\n",
    "data_test = dataset[dataset[\"split\"] == \"test\"][[\"smiles\", \"y\"]]\n",
    "data_train, data_val = train_test_split(data_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed66e1-5365-4be2-8771-f929bce05202",
   "metadata": {},
   "source": [
    "### 2. Build multiple MIL models models with conformers as instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b18eff-a32c-4e24-9bd5-c8700af96d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lazy_mil = LazyMIL(task=\"regression\", hopt=False, output_folder=\"ace_bench_default_2034\", n_cpu=20, verbose=True)\n",
    "lazy_mil.run(data_train, data_val, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc53fd8-7b77-43d9-aff0-4322e5bae5c7",
   "metadata": {},
   "source": [
    "### 3. Build model consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d8254-0ea7-4e4b-b433-b86b60f21b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"auto\"\n",
    "cons_size = \"auto\"\n",
    "\n",
    "cons_size_candidates = [2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69d740-14df-4bd3-bf68-cdf2dfa9a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_methods = [\n",
    "    (\"Best\", SystematicSearchRegressor(cons_size=1, cons_size_candidates=cons_size_candidates, metric=metric)),\n",
    "    \n",
    "    (\"Random\", RandomSearchRegressor(cons_size=cons_size, cons_size_candidates=cons_size_candidates, n_iter=1000, metric=metric)), \n",
    "    \n",
    "    (\"Systematic\", SystematicSearchRegressor(cons_size=cons_size, cons_size_candidates=cons_size_candidates, metric=metric)),\n",
    "    \n",
    "    (\"Genetic\", GeneticSearchRegressor(cons_size=cons_size, n_iter=50, cons_size_candidates=cons_size_candidates, \n",
    "                                       pop_size=50, mut_prob=0.2, metric=metric))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bec8be-dd6a-4511-9ed7-49b75c0d9875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model predictions\n",
    "df_val = pd.read_csv(\"ace_bench_default_2034/val.csv\")\n",
    "df_test = pd.read_csv(\"ace_bench_default_2034/test.csv\")\n",
    "\n",
    "# skip first two columns (smiles and true property value)\n",
    "x_val, true_val = df_val.iloc[:, 2:], df_val.iloc[:, 1]\n",
    "x_test = df_test.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c84355-d2ac-4439-87de-ded949553f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, cons_searcher in cons_methods:\n",
    "\n",
    "    # run search\n",
    "    best_cons = cons_searcher.run(x_val, true_val)\n",
    "    \n",
    "    # make val and test predictions\n",
    "    pred_val = cons_searcher._consensus_predict(x_val[best_cons])\n",
    "    pred_test = cons_searcher._consensus_predict(x_test[best_cons])\n",
    "    \n",
    "    # write prediction accuracy metric\n",
    "    df_val[name] = pred_val\n",
    "    df_test[name] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91fc187-8f72-4924-92eb-f2fd7462f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d580fdf-ff9a-40e0-b544-9890782a18b4",
   "metadata": {},
   "source": [
    "### 4. Summurize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130964c4-0e19-48a1-aa01-b9a82a6f2eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "for model in df_val.columns[2:]:\n",
    "    res.loc[model, \"R2\"] = r2_score(df_val[\"Y_TRUE\"], df_val[model])\n",
    "res.sort_values(by=\"R2\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7afb400-1dd3-4fe4-9b2c-b0faba8ea8d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "for model in df_test.columns[2:]:\n",
    "    res.loc[model, \"R2\"] = r2_score(df_test[\"Y_TRUE\"], df_test[model])\n",
    "res.sort_values(by=\"R2\", ascending=False).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19791f20-5ca4-4807-9e75-51528f02c4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f75052-db1a-4de3-9bf8-aa49b1ee8531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3d559-232b-4c1d-8952-5d754f3fb0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be9969-c15c-4288-a320-8c371e005996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milearn",
   "language": "python",
   "name": "milearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
